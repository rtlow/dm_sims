{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/ryan/Data/Data0/.Trash-1000', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_powerm2m2_sigma10', '/home/ryan/Data/Data0/run_CDM_L3N128_HY_var6', '/home/ryan/Data/Data0/run_CDM_L3N128_HY_var2', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma1', '/home/ryan/Data/Data0/run_2cDM_L3N256_HY_power00_sigma100', '/home/ryan/Data/Data0/lost+found', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_power00_sigma0.1', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_powerm2m2_sigma0.1', '/home/ryan/Data/Data0/other', '/home/ryan/Data/Data0/run_2cDM_L3N256_HY_power00_sigma0.1', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_var2', '/home/ryan/Data/Data0/run_2cDM_L3N128_DM_power00_sigma0.1', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_var5', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_power00_sigma1', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_power00_sigma100', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_10e-7', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_power00_sigma10', '/home/ryan/Data/Data0/run_2cDM_L3N256_DM_powerm2m2_sigma1', '/home/ryan/Data/Data0/run_CDM_L3N128_HY_var3', '/home/ryan/Data/Data0/run_CDM_L3N128_HY', '/home/ryan/Data/Data0/run_CDM_L3N128_HY_var4', '/home/ryan/Data/Data0/run_CDM_L3N128_DM', '/home/ryan/Data/Data0/run_CDM_L3N128_HY_var5', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_var6', '/home/ryan/Data/Data0/run_CDM_L3N256_DM', '/home/ryan/Data/Data0/run_CDM_L3N256_HY', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_var4', '/home/ryan/Data/Data0/run_2cDM_L3N128_HY_power00_sigma0.1_var3', '/home/ryan/Data/Data0/run_2cDM_L3N256_HY_power00_sigma1', '/home/ryan/Data/Data4/run_2cDM_L3N256_DM_power22_sigma1', '/home/ryan/Data/Data4/lost+found', '/home/ryan/Data/Data4/run_2cDM_L3N256_HY_power22_sigma1', '/home/ryan/Data/Data4/run_2cDM_L3N256_DM_power22_sigma10', '/home/ryan/Data/Data2/lost+found', '/home/ryan/Data/Data2/run_2cDM_L3N512_HY_power00_sigma1', '/home/ryan/Data/Data2/run_CDM_L3N512_HY', '/home/ryan/Data/Data1/run_CDM_L3N512_DM', '/home/ryan/Data/Data1/lost+found', '/home/ryan/Data/Data1/run_2cDM_L3N512_DM_power00_sigma1', '/home/ryan/Data/Data3/run_2cDM_710_DM_power00_sigma1', '/home/ryan/Data/Data3/run_2cDM_L3N256_HY_powerm2m2_sigma1', '/home/ryan/Data/Data3/run_2cDM_710_DM_powerm2m2_sigma1', '/home/ryan/Data/Data3/run_2cDM_710_HY_power00_sigma1', '/home/ryan/Data/Data3/run_2cDM_L3N256_HY_powerm2m2_sigma0.1', '/home/ryan/Data/Data3/run_CDM_710_DM', '/home/ryan/Data/Data3/lost+found', '/home/ryan/Data/Data3/run_2cDM_710_HY_powerm2m2_sigma1', '/home/ryan/Data/Data3/run_2cDM_L3N256_HY_powerm2m2_sigma10', '/home/ryan/Data/Data3/run_CDM_710_HY']\n"
     ]
    }
   ],
   "source": [
    "outdir = '../data_prods/'\n",
    "data_dir = '/home/ryan/Data'\n",
    "subdirs = [os.path.join(data_dir, o) for o in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir,o))]\n",
    "\n",
    "subdir_list = []\n",
    "for subdir in subdirs:\n",
    "    subdir_list += [os.path.join(subdir, o) for o in os.listdir(subdir) if os.path.isdir(os.path.join(subdir,o))]\n",
    "\n",
    "print(subdir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parsePower(powerType):\n",
    "    stripped = powerType[5:]\n",
    "    negFlag = False\n",
    "    powers = [] \n",
    "    for char in stripped:\n",
    "        if char == 'm':\n",
    "            negFlag = True\n",
    "            continue\n",
    "        if negFlag:\n",
    "            powers.append(-int(char))\n",
    "            negFlag = False\n",
    "        else:\n",
    "            powers.append(int(char))\n",
    "\n",
    "    return powers\n",
    "\n",
    "def parseSigma(sigmaType):\n",
    "    return float(sigmaType[5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_profile(f):\n",
    "\n",
    "    Subhalo=f.get('Subhalo')\n",
    "    SubhaloMass=np.array(Subhalo['SubhaloMass'])\n",
    "    SubhaloMass=10**10*SubhaloMass #converting to solar masses\n",
    "\n",
    "    a=min(SubhaloMass)/2\n",
    "    Mass_Bins=[]\n",
    "    i=1\n",
    "    while a<max(SubhaloMass):\n",
    "        Mass_Bins.append(a)\n",
    "        a=np.power(2,i/2)*min(SubhaloMass)\n",
    "        i=i+1\n",
    "\n",
    "    i=0\n",
    "    j=0\n",
    "    N_halo=[]\n",
    "    for mbin in Mass_Bins:\n",
    "        N_halo.append( (SubhaloMass > mbin).sum() )\n",
    "    return Mass_Bins, N_halo\n",
    "\n",
    "def get_mvel_profile(f):\n",
    "\n",
    "    Subhalo=f.get('Subhalo') #Subhalo is the group, SubhaloVMas is the dataset inside the group\n",
    "    SubhaloVMax=np.array(Subhalo['SubhaloVmax']) #km/s\n",
    "\n",
    "    #Take Absolute Values of the velocities\n",
    "\n",
    "    MaxVel=np.absolute(SubhaloVMax)\n",
    "\n",
    "    #Gotta Create a maximum velocity bin\n",
    "\n",
    "    a=0.5*min(MaxVel)\n",
    "    MaxVel_Bin=[]\n",
    "    while a<max(MaxVel):\n",
    "        MaxVel_Bin.append(a)\n",
    "        a=np.power(a,1.01)+a/5\n",
    "\n",
    "    #Doing the magic here\n",
    "\n",
    "    N_halo=[]\n",
    "    i=0\n",
    "    k=0\n",
    "    for vbin in MaxVel_Bin:\n",
    "        N_halo.append( (MaxVel > vbin).sum() )\n",
    "    return MaxVel_Bin, N_halo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data_prods/run_2cDM_L3N256_DM_powerm2m2_sigma10 already exists!\n",
      "../data_prods/run_CDM_L3N128_HY_var6 already exists!\n",
      "../data_prods/run_CDM_L3N128_HY_var2 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_power00_sigma100 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power00_sigma0.1 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_powerm2m2_sigma0.1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_power00_sigma0.1 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_var2 already exists!\n",
      "../data_prods/run_2cDM_L3N128_DM_power00_sigma0.1 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_var5 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power00_sigma100 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_10e-7 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power00_sigma10 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_powerm2m2_sigma1 already exists!\n",
      "../data_prods/run_CDM_L3N128_HY_var3 already exists!\n",
      "../data_prods/run_CDM_L3N128_HY already exists!\n",
      "../data_prods/run_CDM_L3N128_HY_var4 already exists!\n",
      "../data_prods/run_CDM_L3N128_DM already exists!\n",
      "../data_prods/run_CDM_L3N128_HY_var5 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_var6 already exists!\n",
      "../data_prods/run_CDM_L3N256_DM already exists!\n",
      "../data_prods/run_CDM_L3N256_HY already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_var4 already exists!\n",
      "../data_prods/run_2cDM_L3N128_HY_power00_sigma0.1_var3 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power22_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_power22_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_DM_power22_sigma10 already exists!\n",
      "../data_prods/run_2cDM_L3N512_HY_power00_sigma1 already exists!\n",
      "../data_prods/run_CDM_L3N512_HY already exists!\n",
      "../data_prods/run_CDM_L3N512_DM already exists!\n",
      "../data_prods/run_2cDM_L3N512_DM_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_710_DM_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_powerm2m2_sigma1 already exists!\n",
      "../data_prods/run_2cDM_710_DM_powerm2m2_sigma1 already exists!\n",
      "../data_prods/run_2cDM_710_HY_power00_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_powerm2m2_sigma0.1 already exists!\n",
      "../data_prods/run_CDM_710_DM already exists!\n",
      "../data_prods/run_2cDM_710_HY_powerm2m2_sigma1 already exists!\n",
      "../data_prods/run_2cDM_L3N256_HY_powerm2m2_sigma10 already exists!\n",
      "../data_prods/run_CDM_710_HY already exists!\n"
     ]
    }
   ],
   "source": [
    "for subdir in subdir_list:\n",
    "    \n",
    "    #run name is just folder name\n",
    "    run_name = subdir.split('/')[-1]\n",
    "\n",
    "    #reject folders that aren't runs\n",
    "    if 'run' not in run_name:\n",
    "        continue\n",
    "\n",
    "    fpath = os.path.join(outdir, run_name)\n",
    "    try:\n",
    "        os.mkdir(fpath)\n",
    "    except:\n",
    "        print(f'{fpath} already exists!')\n",
    "    \n",
    "    #get info from filename\n",
    "    splitted = run_name.split('_')\n",
    "\n",
    "    dm_type = splitted[1]\n",
    "\n",
    "    # boxPart = splitted[2] # read from snapshot\n",
    "\n",
    "    baryon_type = splitted[3]\n",
    "\n",
    "\n",
    "    run_dict = {\n",
    "        \"run name\": run_name,\n",
    "        \"DM type\": dm_type,\n",
    "        \"baryon_type\": baryon_type\n",
    "    }\n",
    "\n",
    "    if dm_type == 'CDM':\n",
    "        otherInfo = splitted[4:]\n",
    "        run_dict['otherInfo'] = otherInfo\n",
    "    elif dm_type == '2cDM':\n",
    "        powerType = splitted[4]\n",
    "        powerLaws = parsePower(powerType)\n",
    "        sigmaType = splitted[5]\n",
    "        sigma = parseSigma(sigmaType)\n",
    "        otherInfo = splitted[6:]\n",
    "\n",
    "        temp = {\n",
    "            \"powerLaws\": powerLaws,\n",
    "            \"sigma0\": sigma,\n",
    "            \"otherInfo\": otherInfo\n",
    "        }\n",
    "\n",
    "        run_dict.update(temp)\n",
    "\n",
    "\n",
    "\n",
    "    # read info from snapshots/fof \n",
    "    snaps = sorted(glob.glob(subdir + '/snap*'))\n",
    "    fofs = sorted(glob.glob(subdir + '/fof*'))\n",
    "\n",
    "    with h5py.File(snaps[0], 'r') as f:\n",
    "        boxSize = int((f['Header'].attrs['BoxSize'])) # in kpc\n",
    "        NPart = int(np.cbrt(f['Header'].attrs['NumPart_Total'][1]))\n",
    "        mass_resolution = f['Header'].attrs['MassTable'][1] * 10**10 # in solar masses\n",
    "        softening_length = boxSize / NPart / 29\n",
    "        temp = {\n",
    "            \"BoxSize\": boxSize,\n",
    "            \"NPart\": NPart,\n",
    "            \"Mass Resolution\": mass_resolution,\n",
    "            \"Softening Length\": softening_length\n",
    "        }\n",
    "\n",
    "        run_dict.update(temp)\n",
    "\n",
    "\n",
    "    redshifts = []\n",
    "    for i, fof in enumerate(fofs):\n",
    "        with h5py.File(fof, 'r') as f:\n",
    "            \n",
    "            redshifts.append( float(\"{:.2f}\".format(f['Header'].attrs['Redshift'])) )\n",
    "\n",
    "            try:\n",
    "                mbins, mcount = get_mass_profile(f)\n",
    "                tname = os.path.join(fpath, \"mass_profile_{}.txt\".format(i))\n",
    "                np.savetxt(tname, (mbins, mcount))\n",
    "                vbins, vcount = get_mvel_profile(f)\n",
    "                tname = os.path.join(fpath, \"vel_profile_{}.txt\".format(i))\n",
    "                np.savetxt(tname, (vbins, vcount))\n",
    "            except KeyError:\n",
    "                continue\n",
    "\n",
    "    run_dict['redshifts'] = redshifts\n",
    "\n",
    "    fname = os.path.join(fpath, \"run_info.json\")\n",
    "    with open(fname, 'w') as outfile:\n",
    "        json.dump(run_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
